{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = ['data',]\n",
    "### csv must be  id|xxx|xxx|nose|LEye.......\n",
    "\n",
    "alphaI2W = [ \"nose\",\"LEye\",\"REye\",\"LEar\",\"REar\",\"LShoulder\",\"RShoulder\", \"LElbow\",\"RElbow\",\\\n",
    "\"LWrist\", \"RWrist\",\"LHip\",\"RHip\", \"LKnee\",\"Rknee\", \"LAnkle\",\"RAnkle\"]\n",
    "\n",
    "tagI2W = [\"Fall\",\"Stand\", \"Tie\"] # 9\n",
    "tagW2I = {w:i for i,w in enumerate(tagI2W)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagW2I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaI2W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "parpath = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parpath)\n",
    "\n",
    "_=torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 3000\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE = True\n",
    "INPUT_DIM = 34\n",
    "CLASS_NUM = len(tagI2W)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actRec.models import dnnSingle\n",
    "model = dnnSingle(INPUT_DIM,CLASS_NUM,initrange=1.5).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SinglePoseDataset\n",
    "from actRec.F import normalize_min_\n",
    "\n",
    "class ReadPoseDataset():\n",
    "    def __init__(self, csvdirpath,use_large=True):\n",
    "        data  = []\n",
    "        label = []\n",
    "        for csv_dir_path in csvdirpath:\n",
    "            csvlist = os.listdir(csv_dir_path)\n",
    "            for FileName in csvlist:\n",
    "                #verifies file ends with .csv extension\n",
    "                if(os.path.isdir(FileName)):continue\n",
    "                if(os.path.splitext(FileName)[1] != '.csv'):continue    \n",
    "                CSVFile = os.path.join(csv_dir_path,FileName)\n",
    "                #read csv file\n",
    "                KP_df = pd.read_csv(CSVFile)\n",
    "                #skipping (0-3) colomns , return values of all rows and columns from 4 to last\n",
    "                features = KP_df.iloc[:,4:].values\n",
    "                #return values of pose_class \n",
    "                pose_class = KP_df['pos_class'].values\n",
    "                #normalize keypoints \n",
    "                normalize_min_(features)\n",
    "                print(features.shape)\n",
    "                for feats, lbs in zip(features, pose_class):\n",
    "                    data.append(feats)\n",
    "                    label.append(tagW2I[lbs])\n",
    "\n",
    "        self.dataset = np.array(data)\n",
    "        self.labels  = np.array(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def split(self,test_size=0.2, random_state=42):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.dataset, self.labels, test_size=test_size, random_state=random_state)\n",
    "        return SinglePoseDataset(X_train,Y_train), SinglePoseDataset(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = ReadPoseDataset(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read.labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadPoseDataset(DATA_PATH).__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = ReadPoseDataset(DATA_PATH).split()\n",
    "train_data.X.shape, train_data.Y.shape, test_data.X.shape, test_data.Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadPoseDataset(DATA_PATH).__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=SHUFFLE)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE,shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(batch):\n",
    "    label_ = torch.LongTensor(batch['label']).to(device)\n",
    "    input_= batch['data'].to(device)\n",
    "    \n",
    "    out = model(input_) # data,datalen\n",
    "    loss = criterion(out, label_)\n",
    "    #print(out, label_)\n",
    "    batch_acc = (out.argmax(1) == label_).sum().item()\n",
    "    return loss,batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "optimizer = optim.Adadelta(model.parameters())\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 100, gamma=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import procession as pc\n",
    "import time\n",
    "_epoch = -1\n",
    "\n",
    "t = time.localtime(time.time())\n",
    "timestr = '%d-%d-%d_%d-%d'%(t[0],t[1],t[2],t[3],t[4])\n",
    "savepath = 'model/act_dnnSingle%d_'%len(tagI2W)\n",
    "savepath +=timestr\n",
    "\n",
    "os.chdir(parpath)\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import hiddenlayer as hl\n",
    "\n",
    "train_his = hl.History()\n",
    "vaild_his = hl.History()\n",
    "canvas1 = hl.Canvas()\n",
    "for epoch in range(_epoch+1,N_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = pc.train_epoch(model,train_loader,model_eval,optimizer,scheduler,BATCH_SIZE)\n",
    "    valid_loss, valid_acc = pc.evaluate(model,test_loader,model_eval,BATCH_SIZE)\n",
    "    train_his.log(epoch, loss=train_loss, accuracy=train_acc)\n",
    "    vaild_his.log(epoch, loss=valid_loss, accuracy=valid_acc)\n",
    "    with canvas1:\n",
    "        canvas1.draw_plot([train_his[\"loss\"], vaild_his[\"loss\"]],labels=[\"train\", \"vaild\"])\n",
    "        canvas1.draw_plot([train_his[\"accuracy\"], vaild_his[\"accuracy\"]],labels=[\"train\", \"vaild\"])\n",
    "    pc.print_train_info(start_time,epoch,train_loss,train_acc,valid_loss,valid_acc)\n",
    "    _epoch=epoch\n",
    "    info =  {'train_loss':train_loss,'train_acc':train_acc,'valid_loss':valid_loss,'valid_acc':valid_acc}\n",
    "    if epoch % 500 ==0 and epoch != 0: \n",
    "        pc.save_model_with_info(model,optimizer,tagI2W,info,epoch,savepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alphapose] *",
   "language": "python",
   "name": "conda-env-alphapose-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
